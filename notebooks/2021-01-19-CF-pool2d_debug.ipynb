{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repath.preprocess.patching.apply_transform import LiuTransform\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, RandomCrop, RandomRotation, Normalize\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "from repath.utils.paths import project_root\n",
    "import repath.data.datasets.camelyon16 as camelyon16\n",
    "from repath.preprocess.tissue_detection import TissueDetectorOTSU\n",
    "from repath.preprocess.patching import GridPatchFinder, SlidesIndex\n",
    "from repath.preprocess.sampling import split_camelyon16, balanced_sample, weighted_random\n",
    "from repath.preprocess.augmentation.augments import Rotate, FlipRotate\n",
    "from repath.utils.seeds import set_seed\n",
    "\n",
    "\"\"\"\n",
    "Global stuff\n",
    "\"\"\"\n",
    "experiment_name = \"liu\"\n",
    "experiment_root = project_root() / \"experiments\" / experiment_name\n",
    "tissue_detector = TissueDetectorOTSU()\n",
    "\n",
    "global_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(global_seed)\n",
    "# index all the patches for the camelyon16 dataset\n",
    "train_data = camelyon16.training()\n",
    "apply_transforms = LiuTransform(label=2, num_transforms=8)\n",
    "patch_finder = GridPatchFinder(labels_level=6, patch_level=0, patch_size=128, stride=128, \n",
    "                               border=171, jitter=8, apply_transforms=apply_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "small_train_data = copy.deepcopy(train_data)\n",
    "small_train_data.paths = small_train_data.paths.iloc[96:98, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>annotation</th>\n",
       "      <th>label</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>normal/normal_098.tif</td>\n",
       "      <td></td>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>normal/normal_099.tif</td>\n",
       "      <td></td>\n",
       "      <td>normal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    slide annotation   label tags\n",
       "96  normal/normal_098.tif             normal     \n",
       "97  normal/normal_099.tif             normal     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing normal_098.tif\n",
      "start 128\n",
      "A shape (3456, 1512)\n",
      "A_w shape (1728, 756, 2, 2)\n",
      "kernel size (2, 2)\n",
      "after border 128\n",
      "indexing normal_099.tif\n",
      "start 128\n",
      "A shape (3368, 1520)\n",
      "A_w shape (1684, 760, 2, 2)\n",
      "kernel size (2, 2)\n",
      "after border 128\n"
     ]
    }
   ],
   "source": [
    "train_patches = SlidesIndex.index_dataset(small_train_data, tissue_detector, patch_finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_patches.patch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repath",
   "language": "python",
   "name": "repath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
