{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/ubuntu/anaconda3/envs/repath/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Experiment logs directory logs/example/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | Backbone | 30.5 M\n",
      "-----------------------------------\n",
      "30.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.5 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:21<00:21, 21.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/repath/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  38%|███▊      | 3/8 [00:20<00:34,  6.98s/it, loss=0.833, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  62%|██████▎   | 5/8 [00:37<00:22,  7.53s/it, loss=0.833, v_num=0]\n",
      "Epoch 0:  75%|███████▌  | 6/8 [00:37<00:12,  6.31s/it, loss=0.833, v_num=0]\n",
      "Epoch 0:  88%|████████▊ | 7/8 [00:38<00:05,  5.44s/it, loss=0.833, v_num=0]\n",
      "Epoch 0: 100%|██████████| 8/8 [00:38<00:00,  4.78s/it, loss=0.833, v_num=0]\n",
      "Epoch 0: 100%|██████████| 8/8 [00:39<00:00,  4.93s/it, loss=0.833, v_num=0]\n",
      "Epoch 1:  38%|███▊      | 3/8 [00:17<00:29,  5.86s/it, loss=0.772, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  62%|██████▎   | 5/8 [00:32<00:19,  6.57s/it, loss=0.772, v_num=0]\n",
      "Epoch 1:  75%|███████▌  | 6/8 [00:33<00:11,  5.51s/it, loss=0.772, v_num=0]\n",
      "Epoch 1:  88%|████████▊ | 7/8 [00:33<00:04,  4.75s/it, loss=0.772, v_num=0]\n",
      "Epoch 1: 100%|██████████| 8/8 [00:33<00:00,  4.18s/it, loss=0.772, v_num=0]\n",
      "Epoch 1: 100%|██████████| 8/8 [00:34<00:00,  4.28s/it, loss=0.772, v_num=0]\n",
      "Epoch 2:  38%|███▊      | 3/8 [00:17<00:28,  5.72s/it, loss=0.733, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  62%|██████▎   | 5/8 [00:33<00:20,  6.71s/it, loss=0.733, v_num=0]\n",
      "Epoch 2:  75%|███████▌  | 6/8 [00:33<00:11,  5.62s/it, loss=0.733, v_num=0]\n",
      "Epoch 2:  88%|████████▊ | 7/8 [00:33<00:04,  4.85s/it, loss=0.733, v_num=0]\n",
      "Epoch 2: 100%|██████████| 8/8 [00:34<00:00,  4.27s/it, loss=0.733, v_num=0]\n",
      "Epoch 2: 100%|██████████| 8/8 [00:35<00:00,  4.43s/it, loss=0.733, v_num=0]\n",
      "Epoch 3:  38%|███▊      | 3/8 [00:17<00:28,  5.70s/it, loss=0.716, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  62%|██████▎   | 5/8 [00:33<00:20,  6.71s/it, loss=0.716, v_num=0]\n",
      "Epoch 3:  75%|███████▌  | 6/8 [00:33<00:11,  5.62s/it, loss=0.716, v_num=0]\n",
      "Epoch 3:  88%|████████▊ | 7/8 [00:33<00:04,  4.85s/it, loss=0.716, v_num=0]\n",
      "Epoch 3: 100%|██████████| 8/8 [00:34<00:00,  4.27s/it, loss=0.716, v_num=0]\n",
      "Epoch 3: 100%|██████████| 8/8 [00:35<00:00,  4.41s/it, loss=0.716, v_num=0]\n",
      "Epoch 4:  38%|███▊      | 3/8 [00:17<00:29,  5.82s/it, loss=0.707, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  62%|██████▎   | 5/8 [00:33<00:20,  6.77s/it, loss=0.707, v_num=0]\n",
      "Epoch 4:  75%|███████▌  | 6/8 [00:34<00:11,  5.67s/it, loss=0.707, v_num=0]\n",
      "Epoch 4:  88%|████████▊ | 7/8 [00:34<00:04,  4.89s/it, loss=0.707, v_num=0]\n",
      "Epoch 4: 100%|██████████| 8/8 [00:34<00:00,  4.31s/it, loss=0.707, v_num=0]\n",
      "Epoch 4: 100%|██████████| 8/8 [00:35<00:00,  4.38s/it, loss=0.707, v_num=0]\n",
      "Epoch 5:  38%|███▊      | 3/8 [00:17<00:28,  5.77s/it, loss=0.703, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  62%|██████▎   | 5/8 [00:33<00:20,  6.77s/it, loss=0.703, v_num=0]\n",
      "Epoch 5:  75%|███████▌  | 6/8 [00:34<00:11,  5.68s/it, loss=0.703, v_num=0]\n",
      "Epoch 5:  88%|████████▊ | 7/8 [00:34<00:04,  4.90s/it, loss=0.703, v_num=0]\n",
      "Epoch 5: 100%|██████████| 8/8 [00:34<00:00,  4.31s/it, loss=0.703, v_num=0]\n",
      "Epoch 5: 100%|██████████| 8/8 [00:35<00:00,  4.40s/it, loss=0.703, v_num=0]\n",
      "Epoch 6:  38%|███▊      | 3/8 [00:16<00:27,  5.41s/it, loss=0.689, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  62%|██████▎   | 5/8 [00:32<00:19,  6.52s/it, loss=0.689, v_num=0]\n",
      "Epoch 6:  75%|███████▌  | 6/8 [00:32<00:10,  5.46s/it, loss=0.689, v_num=0]\n",
      "Epoch 6:  88%|████████▊ | 7/8 [00:33<00:04,  4.72s/it, loss=0.689, v_num=0]\n",
      "Epoch 6: 100%|██████████| 8/8 [00:33<00:00,  4.15s/it, loss=0.689, v_num=0]\n",
      "Epoch 6: 100%|██████████| 8/8 [00:33<00:00,  4.25s/it, loss=0.689, v_num=0]\n",
      "Epoch 7:  38%|███▊      | 3/8 [00:17<00:28,  5.68s/it, loss=0.671, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  62%|██████▎   | 5/8 [00:33<00:20,  6.71s/it, loss=0.671, v_num=0]\n",
      "Epoch 7:  75%|███████▌  | 6/8 [00:33<00:11,  5.63s/it, loss=0.671, v_num=0]\n",
      "Epoch 7:  88%|████████▊ | 7/8 [00:33<00:04,  4.85s/it, loss=0.671, v_num=0]\n",
      "Epoch 7: 100%|██████████| 8/8 [00:34<00:00,  4.27s/it, loss=0.671, v_num=0]\n",
      "Epoch 7: 100%|██████████| 8/8 [00:34<00:00,  4.36s/it, loss=0.671, v_num=0]\n",
      "Epoch 8:  38%|███▊      | 3/8 [00:17<00:29,  5.80s/it, loss=0.658, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  62%|██████▎   | 5/8 [00:32<00:19,  6.44s/it, loss=0.658, v_num=0]\n",
      "Epoch 8:  75%|███████▌  | 6/8 [00:33<00:11,  5.52s/it, loss=0.658, v_num=0]\n",
      "Epoch 8:  88%|████████▊ | 7/8 [00:33<00:04,  4.76s/it, loss=0.658, v_num=0]\n",
      "Epoch 8: 100%|██████████| 8/8 [00:33<00:00,  4.19s/it, loss=0.658, v_num=0]\n",
      "Epoch 8: 100%|██████████| 8/8 [00:34<00:00,  4.28s/it, loss=0.658, v_num=0]\n",
      "Epoch 9:  38%|███▊      | 3/8 [00:17<00:28,  5.72s/it, loss=0.65, v_num=0] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  62%|██████▎   | 5/8 [00:33<00:19,  6.65s/it, loss=0.65, v_num=0]\n",
      "Epoch 9:  75%|███████▌  | 6/8 [00:33<00:11,  5.58s/it, loss=0.65, v_num=0]\n",
      "Epoch 9:  88%|████████▊ | 7/8 [00:33<00:04,  4.81s/it, loss=0.65, v_num=0]\n",
      "Epoch 9: 100%|██████████| 8/8 [00:33<00:00,  4.24s/it, loss=0.65, v_num=0]\n",
      "Epoch 9: 100%|██████████| 8/8 [00:34<00:00,  4.33s/it, loss=0.65, v_num=0]\n",
      "Epoch 10:  38%|███▊      | 3/8 [00:15<00:26,  5.32s/it, loss=0.637, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  62%|██████▎   | 5/8 [00:31<00:18,  6.30s/it, loss=0.637, v_num=0]\n",
      "Epoch 10:  75%|███████▌  | 6/8 [00:31<00:10,  5.29s/it, loss=0.637, v_num=0]\n",
      "Epoch 10:  88%|████████▊ | 7/8 [00:31<00:04,  4.56s/it, loss=0.637, v_num=0]\n",
      "Epoch 10: 100%|██████████| 8/8 [00:32<00:00,  4.02s/it, loss=0.637, v_num=0]\n",
      "Epoch 10: 100%|██████████| 8/8 [00:32<00:00,  4.11s/it, loss=0.637, v_num=0]\n",
      "Epoch 11:  38%|███▊      | 3/8 [00:17<00:29,  5.81s/it, loss=0.625, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  62%|██████▎   | 5/8 [00:32<00:19,  6.55s/it, loss=0.625, v_num=0]\n",
      "Epoch 11:  75%|███████▌  | 6/8 [00:32<00:10,  5.49s/it, loss=0.625, v_num=0]\n",
      "Epoch 11:  88%|████████▊ | 7/8 [00:33<00:04,  4.74s/it, loss=0.625, v_num=0]\n",
      "Epoch 11: 100%|██████████| 8/8 [00:33<00:00,  4.17s/it, loss=0.625, v_num=0]\n",
      "Epoch 11: 100%|██████████| 8/8 [00:34<00:00,  4.25s/it, loss=0.625, v_num=0]\n",
      "Epoch 12:  38%|███▊      | 3/8 [00:16<00:26,  5.34s/it, loss=0.612, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  62%|██████▎   | 5/8 [00:32<00:19,  6.49s/it, loss=0.612, v_num=0]\n",
      "Epoch 12:  75%|███████▌  | 6/8 [00:32<00:10,  5.45s/it, loss=0.612, v_num=0]\n",
      "Epoch 12:  88%|████████▊ | 7/8 [00:32<00:04,  4.70s/it, loss=0.612, v_num=0]\n",
      "Epoch 12: 100%|██████████| 8/8 [00:33<00:00,  4.14s/it, loss=0.612, v_num=0]\n",
      "Epoch 12: 100%|██████████| 8/8 [00:33<00:00,  4.23s/it, loss=0.612, v_num=0]\n",
      "Epoch 13:  38%|███▊      | 3/8 [00:17<00:29,  5.81s/it, loss=0.595, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  62%|██████▎   | 5/8 [00:33<00:20,  6.69s/it, loss=0.595, v_num=0]\n",
      "Epoch 13:  75%|███████▌  | 6/8 [00:34<00:11,  5.68s/it, loss=0.595, v_num=0]\n",
      "Epoch 13:  88%|████████▊ | 7/8 [00:34<00:04,  4.90s/it, loss=0.595, v_num=0]\n",
      "Epoch 13: 100%|██████████| 8/8 [00:34<00:00,  4.31s/it, loss=0.595, v_num=0]\n",
      "Epoch 13: 100%|██████████| 8/8 [00:35<00:00,  4.39s/it, loss=0.595, v_num=0]\n",
      "Epoch 14:  38%|███▊      | 3/8 [00:17<00:29,  5.82s/it, loss=0.583, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  62%|██████▎   | 5/8 [00:33<00:20,  6.71s/it, loss=0.583, v_num=0]\n",
      "Epoch 14:  75%|███████▌  | 6/8 [00:33<00:11,  5.64s/it, loss=0.583, v_num=0]\n",
      "Epoch 14:  88%|████████▊ | 7/8 [00:34<00:04,  4.86s/it, loss=0.583, v_num=0]\n",
      "Epoch 14: 100%|██████████| 8/8 [00:34<00:00,  4.28s/it, loss=0.583, v_num=0]\n",
      "Epoch 14: 100%|██████████| 8/8 [00:34<00:00,  4.36s/it, loss=0.583, v_num=0]\n",
      "Epoch 14: 100%|██████████| 8/8 [00:34<00:00,  4.37s/it, loss=0.583, v_num=0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from repath.patch_classification.models.simple import Backbone\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from repath.utils.paths import project_root\n",
    "\n",
    "experiment_name = \"example\"\n",
    "experiment_root = project_root() / \"experiments\" / \"repath\" / experiment_name\n",
    "save_root = Path(\"/home/ubuntu/repath/experiments\", experiment_name)\n",
    "\n",
    "class PatchClassifier(pl.LightningModule):\n",
    "    def __init__(self, model) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def accuracy(self, logits, labels):\n",
    "        _, pred = torch.max(logits, 1)\n",
    "        accuracy = Accuracy()\n",
    "        accu = accuracy(pred, labels)\n",
    "        return accu\n",
    "\n",
    "    def step(self, batch, batch_idx, label):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        pred = torch.log_softmax(logits, dim=1)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        # accu = self.accuracy(logits, y)\n",
    "        self.log(f\"{label}_loss\", loss)\n",
    "        \n",
    "        correct=pred.argmax(dim=1).eq(y).sum().item()\n",
    "        total=len(y)   \n",
    "        accu = correct / total\n",
    "        self.log(f\"{label}_accuracy\", accu)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "our_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "    \n",
    "# prepare our data\n",
    "batch_size = 512\n",
    "train_set = ImageFolder(root=experiment_root / \"training_patches\", transform=our_transforms)\n",
    "valid_set = ImageFolder(root=experiment_root / \"validation_patches\", transform=our_transforms)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=80)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=80)\n",
    "\n",
    "# configure logging and checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=save_root / \"patch_model\",\n",
    "    filename=f\"checkpoint.ckpt\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# create a logger\n",
    "tb_logger = pl_loggers.CSVLogger('logs/', name='example', version=0)\n",
    "\n",
    "# train our model\n",
    "model = Backbone()\n",
    "classifier = PatchClassifier(model)\n",
    "trainer = pl.Trainer(callbacks=[checkpoint_callback], gpus=8, accelerator=\"dp\", max_epochs=15, \n",
    "                     logger=tb_logger, log_every_n_steps=1)\n",
    "trainer.fit(classifier, train_dataloader=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repath",
   "language": "python",
   "name": "repath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
