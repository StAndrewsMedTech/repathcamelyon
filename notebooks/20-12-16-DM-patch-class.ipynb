{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import densenet121\n",
    "from torchvision.transforms import Compose, ToTensor, RandomCrop, Normalize\n",
    "\n",
    "\n",
    "class PatchClassifier(pl.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        model = densenet121(pretrained=True)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=1000, bias=True),\n",
    "            nn.Linear(1000, 2))\n",
    "        self.model = model\n",
    "\n",
    "    def cross_entropy_loss(self, logits, labels):\n",
    "        return F.nll_loss(logits, labels)\n",
    "\n",
    "    def step(self, batch, batch_idx, label):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        pred = torch.log_softmax(logits, dim=1)\n",
    "        loss = self.cross_entropy_loss(logits, y)\n",
    "        self.log(f\"{label}_loss\", loss)\n",
    "        \n",
    "        correct=pred.argmax(dim=1).eq(y).sum().item()\n",
    "        total=len(y)   \n",
    "        accu = correct / total\n",
    "        self.log(f\"{label}_accuracy\", accu)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), \n",
    "                                    lr=0.1, \n",
    "                                    momentum=0.9, \n",
    "                                    weight_decay=1e-4)          \n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1),\n",
    "            'interval': 'epoch' \n",
    "        }\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/repath/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory /home/ubuntu/repath/experiments/example/patch_model exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/ubuntu/anaconda3/envs/repath/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Experiment logs directory /home/ubuntu/repath/experiments/example/logs/patch_classifier/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | DenseNet | 8.0 M \n",
      "-----------------------------------\n",
      "8.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.0 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4355f60bb12541ecb50512480f79efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/repath/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80826943e6db4b109d996a04cb22ff8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2a456ff7b84c1e9d6f578d90878ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d0cb6821c14761ad4155c2e01996e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbcba9a0028474e8f0027b3f01eae17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4cf71c0c444670a4a06ca153ba61a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51521492f85942bf899daef6e4da795d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933ed5f7cd5c451eb772852783dac146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from repath.utils.paths import project_root\n",
    "\n",
    "experiment_name = \"example\"\n",
    "experiment_root = project_root() / \"experiments\" /  experiment_name\n",
    "\n",
    "transform = Compose([\n",
    "    RandomCrop((240, 240)),\n",
    "    ToTensor(),\n",
    "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# prepare our data\n",
    "batch_size = 64\n",
    "train_set = ImageFolder(experiment_root / \"training_patches\", transform=transform)\n",
    "valid_set = ImageFolder(experiment_root / \"validation_patches\", transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=80)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=80)\n",
    "\n",
    "# configure logging and checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_accuracy\",\n",
    "    dirpath=experiment_root / \"patch_model\",\n",
    "    filename=f\"checkpoint.ckpt\",\n",
    "    save_top_k=1,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_accuracy',\n",
    "   min_delta=0.00,\n",
    "   patience=5,\n",
    "   verbose=False,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "# create a logger\n",
    "csv_logger = pl_loggers.CSVLogger(experiment_root / 'logs', name='patch_classifier', version=0)\n",
    "\n",
    "# train our model\n",
    "classifier = PatchClassifier()\n",
    "trainer = pl.Trainer(callbacks=[checkpoint_callback, early_stop_callback], gpus=8, accelerator=\"dp\", max_epochs=15, \n",
    "                     logger=csv_logger, log_every_n_steps=1)\n",
    "trainer.fit(classifier, train_dataloader=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### previous stuff keeping for reference at mo\n",
    "\n",
    "    \n",
    "# prepare our data\n",
    "batch_size = 128\n",
    "train_set = ImageFolder(root=experiment_root / \"training_patches\")\n",
    "valid_set = ImageFolder(root=experiment_root / \"validation_patches\")\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)\n",
    "\n",
    "# configure logging and checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=experiment_root / \"patch_model\",\n",
    "    filename=f\"checkpoint-{epoch:02d}-{val_loss:.2f}.ckpt\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "our_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "    \n",
    "# prepare our data\n",
    "batch_size = 512\n",
    "train_set = ImageFolder(root=experiment_root / \"training_patches\", transform=our_transforms)\n",
    "valid_set = ImageFolder(root=experiment_root / \"validation_patches\", transform=our_transforms)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=80)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, num_workers=80)\n",
    "\n",
    "# configure logging and checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath= experiment_root / \"patch_model\",\n",
    "    filename=f\"checkpoint.ckpt\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# create a logger\n",
    "tb_logger = pl_loggers.CSVLogger(experiment_root / 'logs', name='patch_classifier', version=0)\n",
    "\n",
    "# train our model\n",
    "model = Backbone()\n",
    "classifier = PatchClassifier(model)\n",
    "trainer = pl.Trainer(callbacks=[checkpoint_callback], gpus=8, accelerator=\"dp\", max_epochs=15, \n",
    "                     logger=tb_logger, log_every_n_steps=1)\n",
    "trainer.fit(classifier, train_dataloader=train_loader, val_dataloaders=valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repath",
   "language": "python",
   "name": "repath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
