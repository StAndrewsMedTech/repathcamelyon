{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/repath/data/test_segment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff8d33763b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"data\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"test_segment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/repath/data/test_segment'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from repath.utils.paths import project_root\n",
    "\n",
    "test_dir = project_root() / \"data\" / \"test_segment\"\n",
    "\n",
    "files = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(test_dir / files[1])\n",
    "\n",
    "half_size = (int(image.size[0] / 2), int(image.size[1] / 2))\n",
    "\n",
    "image = image.resize(half_size)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> a9896e898fa227658bbe8918de4e82ebd319bb5e
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_np(arr_in):\n",
    "    return Image.fromarray(np.array(arr_in, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7efeacaf0a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtissue_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTissueDetectorGreyScale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTissueDetectorOTSU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtissue_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTissueDetectorOTSU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtissue_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtissue_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from repath.preprocess.tissue_detection import TissueDetectorGreyScale, TissueDetectorOTSU\n",
    "\n",
    "image_np = np.array(image)\n",
    "tissue_detector = TissueDetectorOTSU()\n",
    "tissue_mask = tissue_detector(image_np)\n",
    "show_np(tissue_mask*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d_mask = np.expand_dims(tissue_mask, axis=-1)\n",
    "three_d_mask = np.dstack((three_d_mask, three_d_mask, three_d_mask))\n",
    "filtered_image = np.where(np.logical_not(three_d_mask), 0, image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "image_gs = rgb2gray(filtered_image)\n",
    "show_np(image_gs*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active contours - not promising\n",
    "\n",
    "Needs a initially specified starting snake, maybe too manual to get a good automatic result.\n",
    "\n",
    "Need to specify if attracted to dark or light regions\n",
    "\n",
    "Not good performance of finding outer edge using basic values.\n",
    "Seems like it would need a lot of tuning to get something to work on outer edge let alone fine gradations of colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "\n",
    "s = np.linspace(0, 2*np.pi, 400)\n",
    "r = 375 + 200*np.sin(s)\n",
    "c = 275 + 200*np.cos(s)\n",
    "init = np.array([r, c]).T\n",
    "\n",
    "snake = active_contour(gaussian(filtered_image, 3),\n",
    "                       init, alpha=0.005, beta=20, gamma=0.001, w_line=-0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(image_gs, cmap=plt.cm.gray)\n",
    "ax.plot(init[:, 1], init[:, 0], '--r', lw=3)\n",
    "ax.plot(snake[:, 1], snake[:, 0], '-b', lw=3)\n",
    "ax.set_xticks([]), ax.set_yticks([])\n",
    "ax.axis([0, image_gs.shape[1], image_gs.shape[0], 0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chan Vese segmentation - no use\n",
    "\n",
    "Only works on greyscale \n",
    "\n",
    "Only returns a true false segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import chan_vese\n",
    "\n",
    "# Feel free to play around with the parameters to see how they impact the result\n",
    "\n",
    "cv = chan_vese(image_gs, mu=0.25, lambda1=1, lambda2=1, tol=1e-3, max_iter=200,\n",
    "               dt=0.5, init_level_set=\"checkerboard\", extended_output=True)\n",
    "\n",
    "segments_cv = cv[0]\n",
    "levset_cv = cv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(segments_cv*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(levset_cv*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkerboard level set - tool not a segmentation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import checkerboard_level_set\n",
    "\n",
    "init_ls = checkerboard_level_set(image_gs.shape, 6)\n",
    "\n",
    "show_np(init_ls*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circle level set - tool not a segmentation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import circle_level_set\n",
    "\n",
    "init_ls = circle_level_set(image_gs.shape)\n",
    "\n",
    "show_np(init_ls*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear border - tool not a segmentation technique\n",
    "\n",
    "Removes segments on edge of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import clear_border\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "\n",
    "image = data.coins()[50:-50, 50:-50]\n",
    "\n",
    "# apply threshold\n",
    "thresh = threshold_otsu(image)\n",
    "bw = closing(image > thresh, square(3))\n",
    "\n",
    "# remove artifacts connected to image border\n",
    "cleared = clear_border(bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(bw*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(cleared*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## disk_level_set - tool not a segmentation\n",
    "\n",
    "Disk level set cannot import might be a version issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage.segmentation import disk_level_set\n",
    "\n",
    "#init_ls = disk_level_set(image_gs.shape)\n",
    "\n",
    "#show_np(init_ls*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand labels - tool not a segmentation\n",
    "\n",
    "Expand labels cannot import might be a version issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage.segmentation import expand_labels\n",
    "\n",
    "#expanded = expand_labels(tissue_mask, distance=10)\n",
    "\n",
    "#show_np(expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Felzenszwalb segmentation - looks promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "segments_fz = felzenszwalb(filtered_image, scale=100, sigma=0.5, min_size=50)\n",
    "image_fz = mark_boundaries(filtered_image, segments_fz)\n",
    "\n",
    "show_np(image_fz*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find boundaries and mark boundaries - a tool not a segmentation\n",
    "\n",
    "find boundaries creates a mask of lines where segments meet.\n",
    "\n",
    "mark boundaries draws the lines on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "boundaries = find_boundaries(segments_fz)\n",
    "\n",
    "show_np(boundaries*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flood and flood fill - not promising\n",
    "\n",
    "Flood fill changes the original image. flood creates a mask of the flood area\n",
    "\n",
    "Would require a lot of guesswork to get good starting points for flooding\n",
    "\n",
    "May be useful somewhere in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import flood, flood_fill\n",
    "\n",
    "ff_im = flood_fill(image_gs, (350, 275), 0, tolerance=0.15)\n",
    "\n",
    "show_np(ff_im*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mask = flood(image_gs, (350, 275), tolerance=0.15)\n",
    "show_np(f_mask*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse gaussian gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import inverse_gaussian_gradient\n",
    "\n",
    "gimage = inverse_gaussian_gradient(image_gs)\n",
    "\n",
    "show_np(gimage*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_fz_g = felzenszwalb(gimage, scale=100, sigma=0.5, min_size=50)\n",
    "image_fz_g = mark_boundaries(filtered_image, segments_fz)\n",
    "\n",
    "show_np(image_fz_g*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join segmentations\n",
    "\n",
    "joins two segments, pixels are considered to be int he same segment if they are int he same segment in both segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import join_segmentations\n",
    "\n",
    "segments_join = join_segmentations(segments_fz, segments_fz_g)\n",
    "\n",
    "image_join = mark_boundaries(filtered_image, segments_join)\n",
    "\n",
    "show_np(image_join*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Chan Vese - not promising\n",
    "\n",
    "Can only return true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import morphological_chan_vese\n",
    "\n",
    "def store_evolution_in(lst):\n",
    "    \"\"\"Returns a callback function to store the evolution of the level sets in\n",
    "    the given list.\n",
    "    \"\"\"\n",
    "\n",
    "    def _store(x):\n",
    "        lst.append(np.copy(x))\n",
    "\n",
    "    return _store\n",
    "\n",
    "\n",
    "# Initial level set\n",
    "init_ls_mcv = checkerboard_level_set(image_gs.shape, 6)\n",
    "\n",
    "# List with intermediate results for plotting the evolution\n",
    "evolution = []\n",
    "callback = store_evolution_in(evolution)\n",
    "ls = morphological_chan_vese(image_gs, 3, init_level_set=init_ls_mcv, smoothing=2,\n",
    "                             iter_callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_np(ls*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological geodesic active contour - not promising\n",
    "\n",
    "Also only returns true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import (morphological_chan_vese,\n",
    "                                  morphological_geodesic_active_contour,\n",
    "                                  inverse_gaussian_gradient,\n",
    "                                  checkerboard_level_set)\n",
    "\n",
    "\n",
    "# Morphological GAC\n",
    "gimage = inverse_gaussian_gradient(image_gs)\n",
    "\n",
    "# Initial level set\n",
    "init_ls = np.zeros(image_gs.shape, dtype=np.int8)\n",
    "init_ls[10:-10, 10:-10] = 1\n",
    "# List with intermediate results for plotting the evolution\n",
    "evolution = []\n",
    "callback = store_evolution_in(evolution)\n",
    "ls = morphological_geodesic_active_contour(gimage, 230, init_ls,\n",
    "                                           smoothing=1, balloon=-1,\n",
    "                                           threshold=0.69,\n",
    "                                           iter_callback=callback)\n",
    "\n",
    "show_np(ls*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickshift clustering - possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "\n",
    "segments_quick = quickshift(image_np, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "image_quick = mark_boundaries(filtered_image, segments_quick)\n",
    "\n",
    "show_np(image_quick*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random walker - not promising\n",
    "\n",
    "Should deal better with noisy images might be needs a lot of tweaking and understanding to work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import random_walker\n",
    "\n",
    "# The range of the binary image spans over (-1, 1).\n",
    "# We choose the hottest and the coldest pixels as markers.\n",
    "markers = np.zeros(image_gs.shape, dtype=np.uint)\n",
    "markers[image_gs < 0.4] = 1\n",
    "markers[np.logical_and(image_gs < 0.99, image_gs > 0.8)] = 2\n",
    "\n",
    "# Run random walker algorithm\n",
    "labels = random_walker(image_gs, markers, beta=10, mode='bf')\n",
    "\n",
    "show_np(labels*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relabel sequential - tool not segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import relabel_sequential\n",
    "label_field = np.array([1, 1, 5, 5, 8, 99, 42])\n",
    "relab, fw, inv = relabel_sequential(label_field)\n",
    "relab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLIC segmentation - promising\n",
    "\n",
    "k means clustering based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import felzenszwalb, slic, quickshift, watershed\n",
    "\n",
    "segments_slic = slic(image_np, n_segments=1000, compactness=10, sigma=1)\n",
    "image_slic = mark_boundaries(filtered_image, segments_slic)\n",
    "\n",
    "Image.fromarray(np.array(image_slic*255, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed segmentation - promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import felzenszwalb\n",
    "\n",
    "gradient = sobel(rgb2gray(image_np))\n",
    "segments_watershed_compact = watershed(gradient, markers=4000, compactness=0.001)\n",
    "image_wsc = mark_boundaries(filtered_image, segments_watershed_compact)\n",
    "\n",
    "show_np(image_wsc*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_watershed = watershed(gradient, markers=1000, compactness=0)\n",
    "image_ws = mark_boundaries(filtered_image, segments_watershed)\n",
    "\n",
    "show_np(image_ws*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_watershed_g = watershed(gimage, compactness=0)\n",
    "image_ws_g = mark_boundaries(filtered_image, segments_watershed_g)\n",
    "\n",
    "show_np(image_ws_g*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region adjacency graph colour merging from SLIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, segmentation, color\n",
    "from skimage.future import graph\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _weight_mean_color(graph, src, dst, n):\n",
    "    \"\"\"Callback to handle merging nodes by recomputing mean color.\n",
    "\n",
    "    The method expects that the mean color of `dst` is already computed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : RAG\n",
    "        The graph under consideration.\n",
    "    src, dst : int\n",
    "        The vertices in `graph` to be merged.\n",
    "    n : int\n",
    "        A neighbor of `src` or `dst` or both.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        A dictionary with the `\"weight\"` attribute set as the absolute\n",
    "        difference of the mean color between node `dst` and `n`.\n",
    "    \"\"\"\n",
    "\n",
    "    diff = graph.nodes[dst]['mean color'] - graph.nodes[n]['mean color']\n",
    "    diff = np.linalg.norm(diff)\n",
    "    return {'weight': diff}\n",
    "\n",
    "\n",
    "def merge_mean_color(graph, src, dst):\n",
    "    \"\"\"Callback called before merging two nodes of a mean color distance graph.\n",
    "\n",
    "    This method computes the mean color of `dst`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph : RAG\n",
    "        The graph under consideration.\n",
    "    src, dst : int\n",
    "        The vertices in `graph` to be merged.\n",
    "    \"\"\"\n",
    "    graph.nodes[dst]['total color'] += graph.nodes[src]['total color']\n",
    "    graph.nodes[dst]['pixel count'] += graph.nodes[src]['pixel count']\n",
    "    graph.nodes[dst]['mean color'] = (graph.nodes[dst]['total color'] /\n",
    "                                      graph.nodes[dst]['pixel count'])\n",
    "\n",
    "\n",
    "labels = segmentation.slic(filtered_image, compactness=30, n_segments=4000)\n",
    "g = graph.rag_mean_color(filtered_image, labels)\n",
    "\n",
    "labels2 = graph.merge_hierarchical(labels, g, thresh=5, rag_copy=False,\n",
    "                                   in_place_merge=True,\n",
    "                                   merge_func=merge_mean_color,\n",
    "                                   weight_func=_weight_mean_color)\n",
    "\n",
    "out = color.label2rgb(labels2, image_np, kind='avg', bg_label=0)\n",
    "out = mark_boundaries(out, labels2, (0, 0, 0))\n",
    "show_np(out*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_out = mark_boundaries(filtered_image, labels2, (255, 255, 0))\n",
    "show_np(image_out*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Try on a watershed segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = graph.rag_mean_color(filtered_image, segments_watershed_compact)\n",
    "\n",
    "labels_w = graph.merge_hierarchical(segments_watershed_compact, gw, thresh=2, rag_copy=False,\n",
    "                                   in_place_merge=True,\n",
    "                                   merge_func=merge_mean_color,\n",
    "                                   weight_func=_weight_mean_color)\n",
    "\n",
    "out_w = color.label2rgb(labels_w, image_np, kind='avg', bg_label=0)\n",
    "out_w = mark_boundaries(out_w, labels_w, (0, 0, 0))\n",
    "show_np(out_w*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_out_w = mark_boundaries(filtered_image, labels_w, (255, 255, 0))\n",
    "show_np(image_out_w*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating segmentation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()\n",
    "\n",
    "show_np(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificially create a \"true\" segmentation to test against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "elevation_map = sobel(image)\n",
    "markers = np.zeros_like(image)\n",
    "markers[image < 30] = 1\n",
    "markers[image > 150] = 2\n",
    "im_true = watershed(elevation_map, markers)\n",
    "im_true = ndi.label(ndi.binary_fill_holes(im_true - 1))[0]\n",
    "\n",
    "show_np(np.where(im_true > 0, im_true*8+50, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create two segmentations to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges1 = sobel(image)\n",
    "im_test1 = watershed(edges1, markers=468, compactness=0.001)\n",
    "\n",
    "show_np(im_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import img_as_float\n",
    "\n",
    "image = img_as_float(image)\n",
    "gradient = inverse_gaussian_gradient(image)\n",
    "init_ls = np.zeros(image.shape, dtype=np.int8)\n",
    "init_ls[10:-10, 10:-10] = 1\n",
    "im_test2 = morphological_geodesic_active_contour(gradient, iterations=100,\n",
    "                                                 init_level_set=init_ls,\n",
    "                                                 smoothing=1, balloon=-1,\n",
    "                                                 threshold=0.69)\n",
    "im_test2 = label(im_test2)\n",
    "show_np(im_test2*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import adapted_rand_error, variation_of_information\n",
    "\n",
    "error1, precision1, recall1 = adapted_rand_error(im_true, im_test1)\n",
    "splits1, merges1 = variation_of_information(im_true, im_test1)\n",
    "f'error: {error1}, precision: {precision1}, recall: {recall1}, splits: {splits1}, merges: {merges1}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error2, precision2, recall2 = adapted_rand_error(im_true, im_test2)\n",
    "splits2, merges2 = variation_of_information(im_true, im_test2)\n",
    "f'error: {error2}, precision: {precision2}, recall: {recall2}, splits: {splits2}, merges: {merges2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data, segmentation, feature, future\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "\n",
    "full_img = Image.open(test_dir / files[1])\n",
    "\n",
    "full_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img_np = np.array(full_img)\n",
    "\n",
    "img = full_img_np[700:1000, 1500:2000]\n",
    "\n",
    "show_np(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import rectangle_perimeter\n",
    "\n",
    "rr, cc = rectangle_perimeter((0, 160), end=(30,220), shape=img.shape)\n",
    "img[rr, cc, :] = [0, 0, 0]\n",
    "\n",
    "rr, cc = rectangle_perimeter((40, 300), end=(60,350), shape=img.shape)\n",
    "img[rr, cc, :] = [0, 0, 0]\n",
    "\n",
    "rr, cc = rectangle_perimeter((0, 0), end=(30,50), shape=img.shape)\n",
    "img[rr, cc, :] = [0, 0, 0]\n",
    "\n",
    "rr, cc = rectangle_perimeter((160, 80), end=(200, 140), shape=img.shape)\n",
    "img[rr, cc, :] = [0, 0, 0]\n",
    "\n",
    "show_np(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an array of labels for training the segmentation.\n",
    "# Here we use rectangles but visualization libraries such as plotly\n",
    "# (and napari?) can be used to draw a mask on the image.\n",
    "training_labels = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "training_labels[0:30, 160:220] = 1\n",
    "training_labels[40:60, 300:350] = 2\n",
    "training_labels[0:30, 0:50] = 3\n",
    "training_labels[160:200, 80:140] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiscale basic features not in the version we have of scikit so copying in from github source\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "import itertools\n",
    "import numpy as np\n",
    "from skimage import filters, feature\n",
    "from skimage import img_as_float32\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def _texture_filter(gaussian_filtered):\n",
    "    H_elems = [\n",
    "        np.gradient(np.gradient(gaussian_filtered)[ax0], axis=ax1)\n",
    "        for ax0, ax1 in combinations_with_replacement(range(gaussian_filtered.ndim), 2)\n",
    "    ]\n",
    "    eigvals = feature.hessian_matrix_eigvals(H_elems)\n",
    "    return eigvals\n",
    "\n",
    "\n",
    "def _singlescale_basic_features_singlechannel(\n",
    "    img, sigma, intensity=True, edges=True, texture=True\n",
    "):\n",
    "    results = ()\n",
    "    gaussian_filtered = filters.gaussian(img, sigma)\n",
    "    if intensity:\n",
    "        results += (gaussian_filtered,)\n",
    "    if edges:\n",
    "        results += (filters.sobel(gaussian_filtered),)\n",
    "    if texture:\n",
    "        results += (*_texture_filter(gaussian_filtered),)\n",
    "    return results\n",
    "\n",
    "\n",
    "def _mutiscale_basic_features_singlechannel(\n",
    "    img,\n",
    "    intensity=True,\n",
    "    edges=True,\n",
    "    texture=True,\n",
    "    sigma_min=0.5,\n",
    "    sigma_max=16,\n",
    "    num_sigma=None,\n",
    "    num_workers=None,\n",
    "):\n",
    "    \"\"\"Features for a single channel nd image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : ndarray\n",
    "        Input image, which can be grayscale or multichannel.\n",
    "    intensity : bool, default True\n",
    "        If True, pixel intensities averaged over the different scales\n",
    "        are added to the feature set.\n",
    "    edges : bool, default True\n",
    "        If True, intensities of local gradients averaged over the different\n",
    "        scales are added to the feature set.\n",
    "    texture : bool, default True\n",
    "        If True, eigenvalues of the Hessian matrix after Gaussian blurring\n",
    "        at different scales are added to the feature set.\n",
    "    sigma_min : float, optional\n",
    "        Smallest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    sigma_max : float, optional\n",
    "        Largest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    num_sigma : int, optional\n",
    "        Number of values of the Gaussian kernel between sigma_min and sigma_max.\n",
    "        If None, sigma_min multiplied by powers of 2 are used.\n",
    "    num_workers : int or None, optional\n",
    "        The number of parallel threads to use. If set to ``None``, the full\n",
    "        set of available cores are used.\n",
    "    Returns\n",
    "    -------\n",
    "    features : list\n",
    "        List of features, each element of the list is an array of shape as img.\n",
    "    \"\"\"\n",
    "    # computations are faster as float32\n",
    "    img = np.ascontiguousarray(img_as_float32(img))\n",
    "    if num_sigma is None:\n",
    "        num_sigma = int(np.log2(sigma_max) - np.log2(sigma_min) + 1)\n",
    "    sigmas = np.logspace(\n",
    "        np.log2(sigma_min),\n",
    "        np.log2(sigma_max),\n",
    "        num=num_sigma,\n",
    "        base=2,\n",
    "        endpoint=True,\n",
    "    )\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "        out_sigmas = list(\n",
    "            ex.map(\n",
    "                lambda s: _singlescale_basic_features_singlechannel(\n",
    "                    img, s, intensity=intensity, edges=edges, texture=texture\n",
    "                ),\n",
    "                sigmas,\n",
    "            )\n",
    "        )\n",
    "    features = itertools.chain.from_iterable(out_sigmas)\n",
    "    return features\n",
    "\n",
    "\n",
    "def multiscale_basic_features(\n",
    "    image,\n",
    "    multichannel=False,\n",
    "    intensity=True,\n",
    "    edges=True,\n",
    "    texture=True,\n",
    "    sigma_min=0.5,\n",
    "    sigma_max=16,\n",
    "    num_sigma=None,\n",
    "    num_workers=None,\n",
    "):\n",
    "    \"\"\"Local features for a single- or multi-channel nd image.\n",
    "    Intensity, gradient intensity and local structure are computed at\n",
    "    different scales thanks to Gaussian blurring.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Input image, which can be grayscale or multichannel.\n",
    "    multichannel : bool, default False\n",
    "        True if the last dimension corresponds to color channels.\n",
    "    intensity : bool, default True\n",
    "        If True, pixel intensities averaged over the different scales\n",
    "        are added to the feature set.\n",
    "    edges : bool, default True\n",
    "        If True, intensities of local gradients averaged over the different\n",
    "        scales are added to the feature set.\n",
    "    texture : bool, default True\n",
    "        If True, eigenvalues of the Hessian matrix after Gaussian blurring\n",
    "        at different scales are added to the feature set.\n",
    "    sigma_min : float, optional\n",
    "        Smallest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    sigma_max : float, optional\n",
    "        Largest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    num_sigma : int, optional\n",
    "        Number of values of the Gaussian kernel between sigma_min and sigma_max.\n",
    "        If None, sigma_min multiplied by powers of 2 are used.\n",
    "    num_workers : int or None, optional\n",
    "        The number of parallel threads to use. If set to ``None``, the full\n",
    "        set of available cores are used.\n",
    "    Returns\n",
    "    -------\n",
    "    features : np.ndarray\n",
    "        Array of shape ``image.shape + (n_features,)``\n",
    "    \"\"\"\n",
    "    if not any([intensity, edges, texture]):\n",
    "        raise ValueError(\n",
    "                \"At least one of ``intensity``, ``edges`` or ``textures``\"\n",
    "                \"must be True for features to be computed.\"\n",
    "                )\n",
    "    if image.ndim < 3:\n",
    "        multichannel = False\n",
    "    if not multichannel:\n",
    "        image = image[..., np.newaxis]\n",
    "    all_results = (\n",
    "        _mutiscale_basic_features_singlechannel(\n",
    "            image[..., dim],\n",
    "            intensity=intensity,\n",
    "            edges=edges,\n",
    "            texture=texture,\n",
    "            sigma_min=sigma_min,\n",
    "            sigma_max=sigma_max,\n",
    "            num_sigma=num_sigma,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        for dim in range(image.shape[-1])\n",
    "    )\n",
    "    features = list(itertools.chain.from_iterable(all_results))\n",
    "    return np.stack(features, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict segmenter also copied from scikit image v 18\n",
    "\n",
    "def fit_segmenter(labels, features, clf):\n",
    "    \"\"\"Segmentation using labeled parts of the image and a classifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : ndarray of ints\n",
    "        Image of labels. Labels >= 1 correspond to the training set and\n",
    "        label 0 to unlabeled pixels to be segmented.\n",
    "    features : ndarray\n",
    "        Array of features, with the first dimension corresponding to the number\n",
    "        of features, and the other dimensions correspond to ``labels.shape``.\n",
    "    clf : classifier object\n",
    "        classifier object, exposing a ``fit`` and a ``predict`` method as in\n",
    "        scikit-learn's API, for example an instance of\n",
    "        ``RandomForestClassifier`` or ``LogisticRegression`` classifier.\n",
    "    Returns\n",
    "    -------\n",
    "    clf : classifier object\n",
    "        classifier trained on ``labels``\n",
    "    Raises\n",
    "    ------\n",
    "    NotFittedError if ``self.clf`` has not been fitted yet (use ``self.fit``).\n",
    "    \"\"\"\n",
    "    mask = labels > 0\n",
    "    training_data = features[mask]\n",
    "    training_labels = labels[mask].ravel()\n",
    "    clf.fit(training_data, training_labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_segmenter(features, clf):\n",
    "    \"\"\"Segmentation of images using a pretrained classifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : ndarray\n",
    "        Array of features, with the last dimension corresponding to the number\n",
    "        of features, and the other dimensions are compatible with the shape of\n",
    "        the image to segment, or a flattened image.\n",
    "    clf : classifier object\n",
    "        trained classifier object, exposing a ``predict`` method as in\n",
    "        scikit-learn's API, for example an instance of\n",
    "        ``RandomForestClassifier`` or ``LogisticRegression`` classifier. The\n",
    "        classifier must be already trained, for example with\n",
    "        :func:`skimage.segmentation.fit_segmenter`.\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray\n",
    "        Labeled array, built from the prediction of the classifier.\n",
    "    \"\"\"\n",
    "    sh = features.shape\n",
    "    if features.ndim > 2:\n",
    "        features = features.reshape((-1, sh[-1]))\n",
    "\n",
    "    try:\n",
    "        predicted_labels = clf.predict(features)\n",
    "    except NotFittedError:\n",
    "        raise NotFittedError(\n",
    "            \"You must train the classifier `clf` first\"\n",
    "            \"for example with the `fit_segmenter` function.\"\n",
    "        )\n",
    "    except ValueError as err:\n",
    "        if err.args and 'x must consist of vectors of length' in err.args[0]:\n",
    "            raise ValueError(\n",
    "                err.args[0] + '\\n' +\n",
    "                \"Maybe you did not use the same type of features for training the classifier.\"\n",
    "                )\n",
    "    output = predicted_labels.reshape(sh[:-1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_min = 1\n",
    "sigma_max = 16\n",
    "features_func = partial(multiscale_basic_features,\n",
    "                        intensity=True, edges=False, texture=True,\n",
    "                        sigma_min=sigma_min, sigma_max=sigma_max,\n",
    "                        multichannel=True)\n",
    "features = features_func(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1,\n",
    "                             max_depth=10, max_samples=0.05)\n",
    "clf = fit_segmenter(training_labels, features, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_segmenter(features, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 4))\n",
    "ax[0].imshow(segmentation.mark_boundaries(img, result, mode='thick'))\n",
    "ax[0].contour(training_labels)\n",
    "ax[0].set_title('Image, mask and segmentation boundaries')\n",
    "ax[1].imshow(result)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repath",
   "language": "python",
   "name": "repath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
