{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from joblib import dump, load\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import repath.data.datasets.bloodmucus as bloodm\n",
    "from repath.preprocess.patching import GridPatchFinder, SlidesIndex, CombinedIndex\n",
    "from repath.preprocess.tissue_detection import TissueDetectorGreyScale, SizedClosingTransform, FillHolesTransform\n",
    "from repath.preprocess.tissue_detection.blood_mucus import get_slides_annots, apply_tissue_detection, get_features_list, fit_segmenter_multi, predict_segmenter, get_features, pool_blood_mucus, get_annot_areas, calc_confusion_mat_2class, calc_confusion_mat_3class, save_confusion_mat, flatten_mask_annots_list\n",
    "from repath.utils.convert import get_concat_h, get_concat_v\n",
    "from repath.utils.paths import project_root\n",
    "from repath.utils.seeds import set_seed\n",
    "\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "\"\"\"\n",
    "Global stuff\n",
    "\"\"\"\n",
    "experiment_name = \"bloodmucus_lev4_rf\"\n",
    "experiment_root = project_root() / \"experiments\" / experiment_name\n",
    "\n",
    "global_seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(global_seed)\n",
    "level_label = 4\n",
    "\n",
    "# read in slides and annotations for training\n",
    "dset = bloodm.training()\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbz, annotz = get_slides_annots(dset, level_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tissue detection\n",
    "morphology_transform1 = SizedClosingTransform(level_in=level_label)\n",
    "morphology_transform2 = FillHolesTransform(level_in=level_label)\n",
    "morphology_transforms = [morphology_transform1, morphology_transform2]\n",
    "tissue_detector = TissueDetectorGreyScale(grey_level=0.85, morph_transform = morphology_transforms)\n",
    "filtered_thumbz = apply_tissue_detection(thumbz, tissue_detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotz_masked = flatten_mask_annots_list(annotz, filtered_thumbz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import itertools\n",
    "\n",
    "from repath.preprocess.tissue_detection.multiscale_features import _mutiscale_basic_features_singlechannel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_basic_features(\n",
    "    image,\n",
    "    multichannel=False,\n",
    "    intensity=True,\n",
    "    edges=True,\n",
    "    texture=True,\n",
    "    sigma_min=0.5,\n",
    "    sigma_max=16,\n",
    "    num_sigma=None,\n",
    "    num_workers=None,\n",
    "):\n",
    "    \"\"\"Local features for a single- or multi-channel nd image.\n",
    "    Intensity, gradient intensity and local structure are computed at\n",
    "    different scales thanks to Gaussian blurring.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        Input image, which can be grayscale or multichannel.\n",
    "    multichannel : bool, default False\n",
    "        True if the last dimension corresponds to color channels.\n",
    "    intensity : bool, default True\n",
    "        If True, pixel intensities averaged over the different scales\n",
    "        are added to the feature set.\n",
    "    edges : bool, default True\n",
    "        If True, intensities of local gradients averaged over the different\n",
    "        scales are added to the feature set.\n",
    "    texture : bool, default True\n",
    "        If True, eigenvalues of the Hessian matrix after Gaussian blurring\n",
    "        at different scales are added to the feature set.\n",
    "    sigma_min : float, optional\n",
    "        Smallest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    sigma_max : float, optional\n",
    "        Largest value of the Gaussian kernel used to average local\n",
    "        neighbourhoods before extracting features.\n",
    "    num_sigma : int, optional\n",
    "        Number of values of the Gaussian kernel between sigma_min and sigma_max.\n",
    "        If None, sigma_min multiplied by powers of 2 are used.\n",
    "    num_workers : int or None, optional\n",
    "        The number of parallel threads to use. If set to ``None``, the full\n",
    "        set of available cores are used.\n",
    "    Returns\n",
    "    -------\n",
    "    features : np.ndarray\n",
    "        Array of shape ``image.shape + (n_features,)``\n",
    "    \"\"\"\n",
    "    \n",
    "    # create tissue mask\n",
    "    rr = image[:, :, 0] == 255\n",
    "    gg = image[:, :, 0] == 255\n",
    "    bb = image[:, :, 0] == 255\n",
    "    mask = np.logical_not(np.logical_and(np.logical_and(rr, gg), bb))\n",
    "    #mask = mask.flatten()\n",
    "    print(mask.shape, np.sum(mask))\n",
    "\n",
    "    if not any([intensity, edges, texture]):\n",
    "        raise ValueError(\n",
    "                \"At least one of ``intensity``, ``edges`` or ``textures``\"\n",
    "                \"must be True for features to be computed.\"\n",
    "                )\n",
    "    if image.ndim < 3:\n",
    "        multichannel = False\n",
    "    if not multichannel:\n",
    "        image = image[..., np.newaxis]\n",
    "    all_results = (\n",
    "        _mutiscale_basic_features_singlechannel(\n",
    "            image[..., dim],\n",
    "            intensity=intensity,\n",
    "            edges=edges,\n",
    "            texture=texture,\n",
    "            sigma_min=sigma_min,\n",
    "            sigma_max=sigma_max,\n",
    "            num_sigma=num_sigma,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        for dim in range(image.shape[-1])\n",
    "    )\n",
    "    features = list(itertools.chain.from_iterable(all_results))\n",
    "    out = np.stack(features, axis=-1)\n",
    "    print(out.shape)\n",
    "    out = out[mask]\n",
    "    print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(filtered_thumb, sigma_min = 1, sigma_max=16, edges=False):\n",
    "    features_func = partial(multiscale_basic_features,\n",
    "                            intensity=True, edges=edges, texture=True,\n",
    "                            sigma_min=sigma_min, sigma_max=sigma_max,\n",
    "                            multichannel=True)\n",
    "    features = features_func(filtered_thumb)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_list(filtered_thumbz, sigma_min = 1, sigma_max=16, edges=False):\n",
    "\n",
    "    featz = []\n",
    "    for idx, tt in enumerate(filtered_thumbz):\n",
    "        print(idx)\n",
    "        features = get_features(tt, sigma_min, sigma_max, edges)\n",
    "        featz.append(features)\n",
    "\n",
    "    return featz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5054, 9438) 5456908\n",
      "(5054, 9438, 60)\n",
      "(5456908, 60)\n",
      "1\n",
      "(5262, 6350) 4984719\n",
      "(5262, 6350, 60)\n",
      "(4984719, 60)\n",
      "2\n",
      "(4622, 5150) 5747818\n",
      "(4622, 5150, 60)\n",
      "(5747818, 60)\n",
      "3\n",
      "(2022, 1574) 183715\n",
      "(2022, 1574, 60)\n",
      "(183715, 60)\n",
      "4\n",
      "(5006, 5598) 7289375\n",
      "(5006, 5598, 60)\n",
      "(7289375, 60)\n",
      "5\n",
      "(6158, 7758) 24186670\n",
      "(6158, 7758, 60)\n",
      "(24186670, 60)\n",
      "6\n",
      "(5342, 8670) 16517849\n",
      "(5342, 8670, 60)\n",
      "(16517849, 60)\n",
      "7\n",
      "(4878, 4622) 2778122\n",
      "(4878, 4622, 60)\n",
      "(2778122, 60)\n",
      "8\n",
      "(5966, 6750) 11159236\n",
      "(5966, 6750, 60)\n",
      "(11159236, 60)\n",
      "9\n",
      "(3022, 2702) 2433894\n",
      "(3022, 2702, 60)\n",
      "(2433894, 60)\n",
      "10\n",
      "(5726, 6286) 7422023\n",
      "(5726, 6286, 60)\n",
      "(7422023, 60)\n",
      "11\n",
      "(3878, 3470) 2675824\n",
      "(3878, 3470, 60)\n",
      "(2675824, 60)\n",
      "12\n",
      "(3214, 2574) 1818468\n",
      "(3214, 2574, 60)\n",
      "(1818468, 60)\n",
      "13\n",
      "(6142, 8222) 22196962\n",
      "(6142, 8222, 60)\n",
      "(22196962, 60)\n",
      "14\n",
      "(3934, 5646) 2943838\n",
      "(3934, 5646, 60)\n",
      "(2943838, 60)\n",
      "15\n",
      "(5838, 5966) 11467175\n",
      "(5838, 5966, 60)\n",
      "(11467175, 60)\n",
      "16\n",
      "(3470, 6670) 2082307\n",
      "(3470, 6670, 60)\n",
      "(2082307, 60)\n",
      "17\n",
      "(4070, 4070) 3487108\n",
      "(4070, 4070, 60)\n",
      "(3487108, 60)\n",
      "18\n",
      "(6030, 7566) 24099136\n",
      "(6030, 7566, 60)\n",
      "(24099136, 60)\n",
      "19\n",
      "(3086, 3406) 2396909\n",
      "(3086, 3406, 60)\n",
      "(2396909, 60)\n",
      "20\n",
      "(5710, 5646) 8347799\n",
      "(5710, 5646, 60)\n",
      "(8347799, 60)\n",
      "21\n",
      "(5326, 8142) 10069743\n",
      "(5326, 8142, 60)\n",
      "(10069743, 60)\n",
      "22\n",
      "(4174, 5646) 7859905\n",
      "(4174, 5646, 60)\n",
      "(7859905, 60)\n",
      "23\n",
      "(5518, 5454) 7595483\n",
      "(5518, 5454, 60)\n",
      "(7595483, 60)\n",
      "24\n",
      "(2638, 2638) 823772\n",
      "(2638, 2638, 60)\n",
      "(823772, 60)\n",
      "25\n",
      "(2446, 2022) 408764\n",
      "(2446, 2022, 60)\n",
      "(408764, 60)\n",
      "26\n",
      "(3278, 4366) 4083609\n",
      "(3278, 4366, 60)\n",
      "(4083609, 60)\n",
      "27\n",
      "(5454, 7502) 5655268\n",
      "(5454, 7502, 60)\n",
      "(5655268, 60)\n",
      "28\n",
      "(6286, 6478) 8250768\n",
      "(6286, 6478, 60)\n",
      "(8250768, 60)\n",
      "29\n",
      "(5070, 5710) 6660891\n",
      "(5070, 5710, 60)\n",
      "(6660891, 60)\n",
      "30\n",
      "(5470, 6926) 10218027\n",
      "(5470, 6926, 60)\n",
      "(10218027, 60)\n",
      "31\n",
      "(4110, 5854) 3370070\n",
      "(4110, 5854, 60)\n",
      "(3370070, 60)\n",
      "32\n",
      "(5886, 10782) 10565996\n",
      "(5886, 10782, 60)\n",
      "(10565996, 60)\n",
      "33\n",
      "(5518, 7710) 7076973\n",
      "(5518, 7710, 60)\n",
      "(7076973, 60)\n",
      "34\n",
      "(5886, 9150) 18922451\n",
      "(5886, 9150, 60)\n",
      "(18922451, 60)\n",
      "35\n",
      "(5342, 4814) 4810450\n",
      "(5342, 4814, 60)\n",
      "(4810450, 60)\n",
      "36\n",
      "(4558, 3358) 2142327\n",
      "(4558, 3358, 60)\n",
      "(2142327, 60)\n",
      "37\n",
      "(3534, 3086) 1482927\n",
      "(3534, 3086, 60)\n",
      "(1482927, 60)\n",
      "38\n",
      "(5950, 12126) 11794271\n",
      "(5950, 12126, 60)\n",
      "(11794271, 60)\n",
      "39\n",
      "(4430, 4878) 5583642\n",
      "(4430, 4878, 60)\n",
      "(5583642, 60)\n",
      "40\n",
      "(2766, 5390) 543062\n",
      "(2766, 5390, 60)\n",
      "(543062, 60)\n",
      "41\n",
      "(5710, 3214) 7218517\n",
      "(5710, 3214, 60)\n",
      "(7218517, 60)\n",
      "42\n",
      "(3550, 6158) 1742190\n",
      "(3550, 6158, 60)\n",
      "(1742190, 60)\n",
      "43\n",
      "(5822, 9278) 18296385\n",
      "(5822, 9278, 60)\n",
      "(18296385, 60)\n",
      "44\n",
      "(5134, 4366) 5033398\n",
      "(5134, 4366, 60)\n",
      "(5033398, 60)\n",
      "45\n",
      "(5326, 5022) 9526561\n",
      "(5326, 5022, 60)\n",
      "(9526561, 60)\n",
      "46\n",
      "(6238, 7886) 20985449\n",
      "(6238, 7886, 60)\n",
      "(20985449, 60)\n",
      "47\n",
      "(5278, 6750) 12711602\n",
      "(5278, 6750, 60)\n",
      "(12711602, 60)\n",
      "48\n",
      "(4174, 8014) 11863259\n",
      "(4174, 8014, 60)\n",
      "(11863259, 60)\n",
      "49\n",
      "(4638, 6158) 5082759\n",
      "(4638, 6158, 60)\n",
      "(5082759, 60)\n",
      "50\n",
      "(4766, 8862) 4426323\n",
      "(4766, 8862, 60)\n",
      "(4426323, 60)\n",
      "51\n",
      "(5326, 6430) 11640146\n",
      "(5326, 6430, 60)\n",
      "(11640146, 60)\n",
      "52\n",
      "(5902, 6478) 14813407\n",
      "(5902, 6478, 60)\n",
      "(14813407, 60)\n",
      "53\n",
      "(6270, 8606) 14252740\n",
      "(6270, 8606, 60)\n",
      "(14252740, 60)\n",
      "54\n",
      "(5598, 6990) 14773792\n",
      "(5598, 6990, 60)\n",
      "(14773792, 60)\n",
      "55\n",
      "(5774, 7198) 11765459\n",
      "(5774, 7198, 60)\n",
      "(11765459, 60)\n",
      "56\n",
      "(5854, 8350) 9832013\n",
      "(5854, 8350, 60)\n",
      "(9832013, 60)\n",
      "57\n",
      "(6238, 12030) 17457684\n",
      "(6238, 12030, 60)\n",
      "(17457684, 60)\n",
      "58\n",
      "(6286, 7966) 20773633\n",
      "(6286, 7966, 60)\n",
      "(20773633, 60)\n",
      "59\n",
      "(6030, 5086) 10279905\n",
      "(6030, 5086, 60)\n",
      "(10279905, 60)\n"
     ]
    }
   ],
   "source": [
    "featz = get_features_list(filtered_thumbz, edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_segmenter_multi(labels_list, features_list, clf):\n",
    "    \"\"\"Segmentation using labeled parts of the image and a classifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : ndarray of ints\n",
    "        Image of labels. Labels >= 1 correspond to the training set and\n",
    "        label 0 to unlabeled pixels to be segmented.\n",
    "    features : ndarray\n",
    "        Array of features, with the first dimension corresponding to the number\n",
    "        of features, and the other dimensions correspond to ``labels.shape``.\n",
    "    clf : classifier object\n",
    "        classifier object, exposing a ``fit`` and a ``predict`` method as in\n",
    "        scikit-learn's API, for example an instance of\n",
    "        ``RandomForestClassifier`` or ``LogisticRegression`` classifier.\n",
    "    Returns\n",
    "    -------\n",
    "    clf : classifier object\n",
    "        classifier trained on ``labels``\n",
    "    Raises\n",
    "    ------\n",
    "    NotFittedError if ``self.clf`` has not been fitted yet (use ``self.fit``).\n",
    "    \"\"\"\n",
    "    training_data_all = []\n",
    "    training_labels_all = []\n",
    "    for idx, labels in enumerate(labels_list):\n",
    "        # mask = labels > 0\n",
    "        # training_data = features_list[idx][mask]\n",
    "        training_data = features_list[idx]\n",
    "        if idx == 0:\n",
    "            training_data_all = training_data\n",
    "        else:\n",
    "            training_data_all = np.vstack((training_data_all, training_data))\n",
    "        # training_labels = labels[mask].ravel()\n",
    "        print(labels.shape)\n",
    "        training_labels_all = np.hstack((training_labels_all, labels))\n",
    "    print(training_data_all.shape, training_labels_all.shape)\n",
    "    clf.fit(training_data_all, training_labels_all)\n",
    "    print(clf, check_is_fitted(clf))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_mask_annots(annots, image):\n",
    "    print(np.max(image))\n",
    "    rr = image[:, :, 0] == 255\n",
    "    gg = image[:, :, 0] == 255\n",
    "    bb = image[:, :, 0] == 255\n",
    "    mask = np.logical_not(np.logical_and(np.logical_and(rr, gg), bb))\n",
    "    print(mask.shape, annots.shape, np.sum(mask))\n",
    "    annots = annots[mask]\n",
    "    print(annots.shape)\n",
    "    return annots\n",
    "\n",
    "def flatten_mask_annots_list(annotz, thumbz):\n",
    "    annots_out = []\n",
    "    for img, ann in zip(thumbz, annotz):\n",
    "        annot = flatten_mask_annots(ann, img)\n",
    "        annots_out.append(annot)\n",
    "    return annots_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "(5054, 9438) (5054, 9438) 5456908\n",
      "(5456908,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_mask_annots(annotz[0], filtered_thumbz[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5456908,)\n",
      "(4984719,)\n",
      "(5747818,)\n",
      "(183715,)\n",
      "(7289375,)\n",
      "(24186670,)\n",
      "(16517849,)\n",
      "(2778122,)\n",
      "(11159236,)\n",
      "(2433894,)\n",
      "(7422023,)\n",
      "(2675824,)\n",
      "(1818468,)\n",
      "(22196962,)\n",
      "(2943838,)\n",
      "(11467175,)\n",
      "(2082307,)\n",
      "(3487108,)\n",
      "(24099136,)\n",
      "(2396909,)\n",
      "(8347799,)\n",
      "(10069743,)\n",
      "(7859905,)\n",
      "(7595483,)\n",
      "(823772,)\n",
      "(408764,)\n",
      "(4083609,)\n",
      "(5655268,)\n",
      "(8250768,)\n",
      "(6660891,)\n",
      "(10218027,)\n",
      "(3370070,)\n",
      "(10565996,)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 113. GiB for an array with shape (252315124, 60) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3976bd9ae599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_segmenter_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotz_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-89ea231a36f4>\u001b[0m in \u001b[0;36mfit_segmenter_multi\u001b[0;34m(labels_list, features_list, clf)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtraining_data_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtraining_data_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# training_labels = labels[mask].ravel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/repath/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 113. GiB for an array with shape (252315124, 60) and data type float64"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=10, max_samples=0.25)\n",
    "clf = fit_segmenter_multi(annotz_masked, featz, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repath",
   "language": "python",
   "name": "repath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
